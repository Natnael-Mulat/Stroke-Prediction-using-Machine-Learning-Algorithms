{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposed-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10360\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer, roc_curve, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "import pickle\n",
    "\n",
    "data=pd.read_csv('DIG.csv')\n",
    "df=data.copy()\n",
    "df = df.drop(['Unnamed: 0', 'ID'], axis=1)\n",
    "df.head()\n",
    "\n",
    "x = df.drop(['STRK'],axis=1)\n",
    "y=df['STRK']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,shuffle=True,random_state=30)\n",
    "\n",
    "#see data if it is balanced \n",
    "#hint is not balanced \n",
    "\n",
    "#min max scaling \n",
    "# compute statistics on training fold for feature rescaling (min-max)\n",
    "minima = np.min(xtrain, axis=0)\n",
    "maxima = np.max(xtrain, axis=0)\n",
    "\n",
    "# rescale train and test sets\n",
    "xtrain = (xtrain - minima) / (maxima - minima)\n",
    "xtest = (xtest - minima) / (maxima - minima)\n",
    "\n",
    "ytrain.shape\n",
    "columns1 = x.columns\n",
    "df_resampling_x = pd.DataFrame(xtrain, columns = columns1)\n",
    "#print(xtrain)\n",
    "df_resampling_y = pd.DataFrame(ytrain, columns = ['id', 'STRK'])\n",
    "del df_resampling_y['id']\n",
    "concat = [df_resampling_x, df_resampling_y]\n",
    "resampled_train_df = pd.concat(concat, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "ytrain.value_counts()\n",
    "sn.histplot(ytrain)\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X = resampled_train_df.drop(columns = 'STRK')\n",
    "Y = resampled_train_df.STRK\n",
    "smote = SMOTE()\n",
    "xtrain ,ytrain = smote.fit_resample(X ,Y)\n",
    "\n",
    "total = len(resampled_train_df['STRK'])\n",
    "\n",
    "ytrain.value_counts()\n",
    "sn.histplot(ytrain)\n",
    "print(len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virgin-glucose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best score: 0.9776737709933171 with param: {'C': 100000}\n",
      "Best score: 0.9776737709933171 with param: {'C': 100000}\n",
      "1360\n",
      "accuracy_score\n",
      " 0.9830882352941176\n",
      "precision_score\n",
      " 0.7714285714285715\n",
      "recall_score\n",
      " 0.8852459016393442\n",
      "f1_score beta\n",
      " 0.8598726114649681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1283,   16],\n",
       "       [   7,   54]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "#w = [ {0:0.005,1:1.0},{0:1.0,1:1.0}, {0:1.0,1:2.0},{0:1.0,1:4.0}, {0:1.0,1:5}, {0:1.0,1:10}, {0:1.0,1:50}]\n",
    "lr_w=LogisticRegression(max_iter=700000)\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "grid_values_w = {'C':[100000]}\n",
    "grid_lr_acc_w = GridSearchCV(lr_w, param_grid = grid_values_w, cv=5, verbose=10, n_jobs=-1, scoring = score_f1_beta)\n",
    "grid_lr_acc_w.fit(xtrain, ytrain)\n",
    "grid_lr_acc_w.best_params_\n",
    "import pickle\n",
    "filename = 'LOGSMOT.sav'\n",
    "pickle.dump(grid_lr_acc_w, open(filename, 'wb'))\n",
    "print(f'Best score: {grid_lr_acc_w.best_score_} with param: {grid_lr_acc_w.best_params_}')\n",
    "#Predict values based on new parameters\n",
    "\n",
    "print(f'Best score: {grid_lr_acc_w.best_score_} with param: {grid_lr_acc_w.best_params_}')\n",
    "lrgpytest_w= grid_lr_acc_w.predict(xtest)\n",
    "print(len(lrgpytest_w))\n",
    "print('accuracy_score\\n',accuracy_score(ytest,lrgpytest_w))\n",
    "print('precision_score\\n',precision_score(ytest,lrgpytest_w))\n",
    "print('recall_score\\n',recall_score(ytest,lrgpytest_w))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,lrgpytest_w, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,lrgpytest_w)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,lrgpytest_w)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,lrgpytest_w)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,lrgpytest_w)\n",
    "confusion_matrix(ytest,lrgpytest_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "million-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START C=10, degree=2, kernel=rbf..................................\n",
      "[CV 1/5; 1/1] END ................C=10, degree=2, kernel=rbf; total time=   1.0s\n",
      "[CV 2/5; 1/1] START C=10, degree=2, kernel=rbf..................................\n",
      "[CV 2/5; 1/1] END ................C=10, degree=2, kernel=rbf; total time=   1.0s\n",
      "[CV 3/5; 1/1] START C=10, degree=2, kernel=rbf..................................\n",
      "[CV 3/5; 1/1] END ................C=10, degree=2, kernel=rbf; total time=   1.0s\n",
      "[CV 4/5; 1/1] START C=10, degree=2, kernel=rbf..................................\n",
      "[CV 4/5; 1/1] END ................C=10, degree=2, kernel=rbf; total time=   1.0s\n",
      "[CV 5/5; 1/1] START C=10, degree=2, kernel=rbf..................................\n",
      "[CV 5/5; 1/1] END ................C=10, degree=2, kernel=rbf; total time=   1.0s\n",
      "Best score: 0.9996141081902692 with param: {'C': 10, 'degree': 2, 'kernel': 'rbf'}\n",
      "1360\n",
      "accuracy_score\n",
      " 0.9801470588235294\n",
      "precision_score\n",
      " 0.8863636363636364\n",
      "recall_score\n",
      " 0.639344262295082\n",
      "f1_score beta\n",
      " 0.6770833333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1294,    5],\n",
       "       [  22,   39]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "#w = [ {0:1.0,1:1.0},{0:1.0,1:2.0},{0:1.0,1:4.0},{0:1.0,1:5}]\n",
    "lsvc_params1  = {\n",
    "    \"kernel\": ['rbf'],\n",
    "    \"C\" : [10],\n",
    "    'degree': [2,]\n",
    "}\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "lsvc1 =SVC()\n",
    "lsvc_tune1 = GridSearchCV(estimator = lsvc1, param_grid = lsvc_params1, verbose=10, scoring = score_f1_beta, cv = 5, return_train_score = True)\n",
    "lsvc_tune1.fit(xtrain, ytrain)\n",
    "lsvc_tune1.best_params_\n",
    "import pickle\n",
    "filename = 'SVCSMOTE.sav'\n",
    "pickle.dump(lsvc_tune1, open(filename, 'wb'))\n",
    "print(f'Best score: {lsvc_tune1.best_score_} with param: {lsvc_tune1.best_params_}')\n",
    "\n",
    "svc_pred= lsvc_tune1.predict(xtest)\n",
    "print(len(lrgpytest_w))\n",
    "print('accuracy_score\\n',accuracy_score(ytest,svc_pred))\n",
    "print('precision_score\\n',precision_score(ytest,svc_pred))\n",
    "print('recall_score\\n',recall_score(ytest,svc_pred))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,svc_pred, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,svc_pred)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,svc_pred)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,svc_pred)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,svc_pred)\n",
    "confusion_matrix(ytest,svc_pred)\n",
    "#Predict values based on new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "invalid-absence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START learning_rate=0.1, n_estimators=1000........................\n",
      "[CV 1/5; 1/1] END ......learning_rate=0.1, n_estimators=1000; total time=  34.4s\n",
      "[CV 2/5; 1/1] START learning_rate=0.1, n_estimators=1000........................\n",
      "[CV 2/5; 1/1] END ......learning_rate=0.1, n_estimators=1000; total time=  33.6s\n",
      "[CV 3/5; 1/1] START learning_rate=0.1, n_estimators=1000........................\n",
      "[CV 3/5; 1/1] END ......learning_rate=0.1, n_estimators=1000; total time=  33.6s\n",
      "[CV 4/5; 1/1] START learning_rate=0.1, n_estimators=1000........................\n",
      "[CV 4/5; 1/1] END ......learning_rate=0.1, n_estimators=1000; total time=  33.6s\n",
      "[CV 5/5; 1/1] START learning_rate=0.1, n_estimators=1000........................\n",
      "[CV 5/5; 1/1] END ......learning_rate=0.1, n_estimators=1000; total time=  33.6s\n",
      "Best score: 0.9768385541433539 with param: {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "accuracy_score\n",
      " 0.975\n",
      "precision_score\n",
      " 0.7288135593220338\n",
      "recall_score\n",
      " 0.7049180327868853\n",
      "f1_score beta\n",
      " 0.7095709570957096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1283,   16],\n",
       "       [  18,   43]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "ada_1 = AdaBoostClassifier()\n",
    "ada_1_params  = {\n",
    "     \"n_estimators\":[ 1000],\n",
    "    \"learning_rate\" : [ .1]\n",
    "}\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "ada_1_tune = GridSearchCV(estimator = ada_1, param_grid = ada_1_params, scoring = score_f1_beta, cv = 5, return_train_score = True, verbose = 10)\n",
    "ada_1_tune.fit(xtrain, ytrain)\n",
    "ada_1_tune.best_params_\n",
    "import pickle\n",
    "filename = 'ADASMOTE.sav'\n",
    "pickle.dump(ada_1_tune, open(filename, 'wb'))\n",
    "print(f'Best score: {ada_1_tune.best_score_} with param: {ada_1_tune.best_params_}')\n",
    "#Predict values based on new parameters\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "ada_1_preds = ada_1_tune.predict(xtest)\n",
    "print('accuracy_score\\n',accuracy_score(ytest,ada_1_preds))\n",
    "print('precision_score\\n',precision_score(ytest,ada_1_preds))\n",
    "print('recall_score\\n',recall_score(ytest,ada_1_preds))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,ada_1_preds, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,ada_1_preds)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,ada_1_preds)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,ada_1_preds)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,ada_1_preds)\n",
    "confusion_matrix(ytest,ada_1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inner-learning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START criterion=gini, n_estimators=1000...........................\n",
      "[CV 1/5; 1/1] END .........criterion=gini, n_estimators=1000; total time=  24.4s\n",
      "[CV 2/5; 1/1] START criterion=gini, n_estimators=1000...........................\n",
      "[CV 2/5; 1/1] END .........criterion=gini, n_estimators=1000; total time=  24.2s\n",
      "[CV 3/5; 1/1] START criterion=gini, n_estimators=1000...........................\n",
      "[CV 3/5; 1/1] END .........criterion=gini, n_estimators=1000; total time=  23.7s\n",
      "[CV 4/5; 1/1] START criterion=gini, n_estimators=1000...........................\n",
      "[CV 4/5; 1/1] END .........criterion=gini, n_estimators=1000; total time=  23.8s\n",
      "[CV 5/5; 1/1] START criterion=gini, n_estimators=1000...........................\n",
      "[CV 5/5; 1/1] END .........criterion=gini, n_estimators=1000; total time=  23.7s\n",
      "accuracy_score\n",
      " 0.9742647058823529\n",
      "precision_score\n",
      " 1.0\n",
      "recall_score\n",
      " 0.4262295081967213\n",
      "f1_score beta\n",
      " 0.4814814814814814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1299,    0],\n",
       "       [  35,   26]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "rfc_1 = RandomForestClassifier()\n",
    "rfc_1_params  = {\n",
    "    \"n_estimators\":[ 1000],\n",
    "    \"criterion\" : ['gini'],\n",
    "}\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "rfc_1_tune = GridSearchCV(estimator = rfc_1, param_grid = rfc_1_params, cv = 5, scoring=score_f1_beta, return_train_score = True, verbose = 10)\n",
    "rfc_1_tune.fit(xtrain, ytrain)\n",
    "rfc_1_tune.best_params_\n",
    "filename = 'RFCSMOTE.sav'\n",
    "pickle.dump(rfc_1_tune, open(filename, 'wb'))\n",
    "rfc_1_preds = rfc_1_tune.predict(xtest)\n",
    "print('accuracy_score\\n',accuracy_score(ytest,rfc_1_preds))\n",
    "print('precision_score\\n',precision_score(ytest,rfc_1_preds))\n",
    "print('recall_score\\n',recall_score(ytest,rfc_1_preds))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,rfc_1_preds, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,rfc_1_preds)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,rfc_1_preds)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,rfc_1_preds)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,rfc_1_preds)\n",
    "confusion_matrix(ytest,rfc_1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "equipped-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam\n",
      "[CV 1/5; 1/1] END activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam; total time=   8.4s\n",
      "[CV 2/5; 1/1] START activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam\n",
      "[CV 2/5; 1/1] END activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam; total time=   9.2s\n",
      "[CV 3/5; 1/1] START activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam\n",
      "[CV 3/5; 1/1] END activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam; total time=   8.6s\n",
      "[CV 4/5; 1/1] START activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam\n",
      "[CV 4/5; 1/1] END activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam; total time=   8.2s\n",
      "[CV 5/5; 1/1] START activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam\n",
      "[CV 5/5; 1/1] END activation=relu, alpha=1e-05, learning_rate=adaptive, solver=adam; total time=   8.6s\n",
      "accuracy_score\n",
      " 0.9838235294117647\n",
      "precision_score\n",
      " 0.8823529411764706\n",
      "recall_score\n",
      " 0.7377049180327869\n",
      "f1_score beta\n",
      " 0.7627118644067798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1293,    6],\n",
       "       [  16,   45]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "parameter_space = {\n",
    "    'activation': ['relu'],\n",
    "    'solver': [ 'adam'],\n",
    "    'alpha': [.00001],\n",
    "    'learning_rate': ['adaptive'],\n",
    "}\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "mlp_gs = MLPClassifier(max_iter=10000)\n",
    "clf = GridSearchCV(mlp_gs, parameter_space, cv=5, scoring=score_f1_beta, verbose=10)\n",
    "clf.fit(xtrain, ytrain)\n",
    "clf.best_params_\n",
    "import pickle\n",
    "filename = 'MLPSMOTE.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "clf_preds = clf.predict(xtest)\n",
    "print('accuracy_score\\n',accuracy_score(ytest,clf_preds))\n",
    "print('precision_score\\n',precision_score(ytest,clf_preds))\n",
    "print('recall_score\\n',recall_score(ytest,clf_preds))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,clf_preds, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,clf_preds)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,clf_preds)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,clf_preds)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,clf_preds)\n",
    "confusion_matrix(ytest,clf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "infinite-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC log:  0.9364643672938832\n",
      "AUC_ROC ada:  0.8463004328676536\n",
      "AUC_ROC svc:  0.8177475737957319\n",
      "AUC_ROC rfc:  0.7131147540983607\n",
      "AUC_ROC mlp:  0.8665429901942225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC_ROC log: \", roc_auc_score(ytest, lrgpytest_w))\n",
    "print(\"AUC_ROC ada: \", roc_auc_score(ytest, ada_1_preds))\n",
    "print(\"AUC_ROC svc: \", roc_auc_score(ytest, svc_pred))\n",
    "print(\"AUC_ROC rfc: \", roc_auc_score(ytest, rfc_1_preds))\n",
    "print(\"AUC_ROC mlp: \", roc_auc_score(ytest,clf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-wildlife",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
