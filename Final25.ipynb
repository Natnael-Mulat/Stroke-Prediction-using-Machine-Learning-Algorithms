{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nonprofit-bridal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5440,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer, roc_curve, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "import pickle\n",
    "\n",
    "data=pd.read_csv('DIG.csv')\n",
    "df=data.copy()\n",
    "df = df.drop(['Unnamed: 0', 'ID'], axis=1)\n",
    "df.head()\n",
    "\n",
    "x = df.drop(['STRK'],axis=1)\n",
    "y=df['STRK']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,shuffle=True,random_state=30)\n",
    "\n",
    "#see data if it is balanced \n",
    "#hint is not balanced \n",
    "\n",
    "#min max scaling \n",
    "# compute statistics on training fold for feature rescaling (min-max)\n",
    "minima = np.min(xtrain, axis=0)\n",
    "maxima = np.max(xtrain, axis=0)\n",
    "\n",
    "# rescale train and test sets\n",
    "xtrain = (xtrain - minima) / (maxima - minima)\n",
    "xtest = (xtest - minima) / (maxima - minima)\n",
    "\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "humanitarian-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO STROKE:  5180\n",
      "STROKE:  260\n",
      "NO STROKE:  3886\n",
      "STROKE:  260\n"
     ]
    }
   ],
   "source": [
    "columns1 = x.columns\n",
    "df_resampling_x = pd.DataFrame(xtrain, columns = columns1)\n",
    "#print(xtrain)\n",
    "df_resampling_y = pd.DataFrame(ytrain, columns = ['id', 'STRK'])\n",
    "del df_resampling_y['id']\n",
    "concat = [df_resampling_x, df_resampling_y]\n",
    "resampled_train_df = pd.concat(concat, axis=1)\n",
    "\n",
    "total = len(resampled_train_df['STRK'])\n",
    "is_stroke = list(resampled_train_df['STRK']).count(1)\n",
    "print(\"NO STROKE: \",total-is_stroke)\n",
    "print(\"STROKE: \",is_stroke)\n",
    "\n",
    "delete_row = resampled_train_df[resampled_train_df[\"STRK\"]==0].index\n",
    "delete_row = delete_row.values[:1294]\n",
    "resampled_train_df= resampled_train_df.drop(delete_row)\n",
    "total = len(resampled_train_df['STRK'])\n",
    "is_stroke = list(resampled_train_df['STRK']).count(1)\n",
    "print(\"NO STROKE: \",total-is_stroke)\n",
    "print(\"STROKE: \",is_stroke)\n",
    "\n",
    "x_train = resampled_train_df.drop(['STRK'],axis=1)\n",
    "y_train = resampled_train_df['STRK']\n",
    "\n",
    "xtrain, x_test,ytrain, y_test = train_test_split(x_train,y_train,test_size=0.0000000000001,shuffle=True,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ongoing-comedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best score: 0.8992798691491674 with param: {'C': 10000, 'class_weight': {0: 1.0, 1: 4.0}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "w = [ {0:1.0,1:4.0}]\n",
    "lr_w=LogisticRegression(max_iter=700000)\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "grid_values_w = {'class_weight':w, 'C':[ 10000]}\n",
    "grid_lr_acc_w = GridSearchCV(lr_w, param_grid = grid_values_w, cv=5, verbose=10, n_jobs=-1,  scoring = score_f1_beta )\n",
    "grid_lr_acc_w.fit(xtrain, ytrain)\n",
    "grid_lr_acc_w.best_params_\n",
    "import pickle\n",
    "filename = 'LOG25%.sav'\n",
    "pickle.dump(grid_lr_acc_w, open(filename, 'wb'))\n",
    "print(f'Best score: {grid_lr_acc_w.best_score_} with param: {grid_lr_acc_w.best_params_}')\n",
    "#Predict values based on new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increased-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8992798691491674 with param: {'C': 10000, 'class_weight': {0: 1.0, 1: 4.0}}\n",
      "accuracy_score\n",
      " 0.9897058823529412\n",
      "precision_score\n",
      " 0.8852459016393442\n",
      "recall_score\n",
      " 0.8852459016393442\n",
      "f1_score beta\n",
      " 0.8852459016393442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1292,    7],\n",
       "       [   7,   54]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Best score: {grid_lr_acc_w.best_score_} with param: {grid_lr_acc_w.best_params_}')\n",
    "lrgpytest_w= grid_lr_acc_w.predict(xtest)\n",
    "print('accuracy_score\\n',accuracy_score(ytest,lrgpytest_w))\n",
    "print('precision_score\\n',precision_score(ytest,lrgpytest_w))\n",
    "print('recall_score\\n',recall_score(ytest,lrgpytest_w))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,lrgpytest_w, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,lrgpytest_w)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,lrgpytest_w)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,lrgpytest_w)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,lrgpytest_w)\n",
    "confusion_matrix(ytest,lrgpytest_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "junior-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear\n",
      "[CV 1/5; 1/1] END C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear; total time=  11.7s\n",
      "[CV 2/5; 1/1] START C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear\n",
      "[CV 2/5; 1/1] END C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear; total time=  19.6s\n",
      "[CV 3/5; 1/1] START C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear\n",
      "[CV 3/5; 1/1] END C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear; total time=   9.0s\n",
      "[CV 4/5; 1/1] START C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear\n",
      "[CV 4/5; 1/1] END C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear; total time=  21.0s\n",
      "[CV 5/5; 1/1] START C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear\n",
      "[CV 5/5; 1/1] END C=1000, class_weight={0: 1.0, 1: 4.0}, degree=2, kernel=linear; total time=  23.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'class_weight': {0: 1.0, 1: 4.0}, 'degree': 2, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "w = [ {0:1.0,1:4.0}]\n",
    "lsvc_params1  = {\n",
    "    \"kernel\": ['linear'],\n",
    "    \"C\" : [1000],\n",
    "    'class_weight':w,\n",
    "    'degree': [2]\n",
    "}\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "lsvc1 =SVC()\n",
    "lsvc_tune1 = GridSearchCV(estimator = lsvc1, param_grid = lsvc_params1, verbose=10, scoring = score_f1_beta, cv = 5, return_train_score = True)\n",
    "lsvc_tune1.fit(xtrain, ytrain)\n",
    "lsvc_tune1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "synthetic-appeal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9247711638738675 with param: {'C': 1000, 'class_weight': {0: 1.0, 1: 4.0}, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'SVC25%.sav'\n",
    "pickle.dump(lsvc_tune1, open(filename, 'wb'))\n",
    "print(f'Best score: {lsvc_tune1.best_score_} with param: {lsvc_tune1.best_params_}')\n",
    "#Predict values based on new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coastal-brisbane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      " 0.9926470588235294\n",
      "precision_score\n",
      " 0.9180327868852459\n",
      "recall_score\n",
      " 0.9180327868852459\n",
      "f1_score beta\n",
      " 0.9180327868852459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1294,    5],\n",
       "       [   5,   56]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "scv_1_preds1 = lsvc_tune1.predict(xtest)\n",
    "print('accuracy_score\\n',accuracy_score(ytest,scv_1_preds1))\n",
    "print('precision_score\\n',precision_score(ytest,scv_1_preds1))\n",
    "print('recall_score\\n',recall_score(ytest,scv_1_preds1))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,scv_1_preds1, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,scv_1_preds1)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,scv_1_preds1)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,scv_1_preds1)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,scv_1_preds1)\n",
    "confusion_matrix(ytest,scv_1_preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beautiful-taylor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START learning_rate=1.5, n_estimators=2500........................\n",
      "[CV 1/5; 1/1] END ......learning_rate=1.5, n_estimators=2500; total time=  24.3s\n",
      "[CV 2/5; 1/1] START learning_rate=1.5, n_estimators=2500........................\n",
      "[CV 2/5; 1/1] END ......learning_rate=1.5, n_estimators=2500; total time=  24.4s\n",
      "[CV 3/5; 1/1] START learning_rate=1.5, n_estimators=2500........................\n",
      "[CV 3/5; 1/1] END ......learning_rate=1.5, n_estimators=2500; total time=  24.3s\n",
      "[CV 4/5; 1/1] START learning_rate=1.5, n_estimators=2500........................\n",
      "[CV 4/5; 1/1] END ......learning_rate=1.5, n_estimators=2500; total time=  24.4s\n",
      "[CV 5/5; 1/1] START learning_rate=1.5, n_estimators=2500........................\n",
      "[CV 5/5; 1/1] END ......learning_rate=1.5, n_estimators=2500; total time=  24.3s\n",
      "Best score: 0.768026405401119 with param: {'learning_rate': 1.5, 'n_estimators': 2500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "ada_1 = AdaBoostClassifier()\n",
    "ada_1_params  = {\n",
    "     \"n_estimators\":[2500],\n",
    "    \"learning_rate\" : [1.5]\n",
    "}\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "ada_1_tune = GridSearchCV(estimator = ada_1, param_grid = ada_1_params, scoring = score_f1_beta, cv = 5, return_train_score = True, verbose = 10)\n",
    "ada_1_tune.fit(xtrain, ytrain)\n",
    "ada_1_tune.best_params_\n",
    "\n",
    "import pickle\n",
    "filename = 'ADA25%.sav'\n",
    "pickle.dump(ada_1_tune, open(filename, 'wb'))\n",
    "print(f'Best score: {ada_1_tune.best_score_} with param: {ada_1_tune.best_params_}')\n",
    "#Predict values based on new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alternative-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      " 0.9845588235294118\n",
      "precision_score\n",
      " 0.8703703703703703\n",
      "recall_score\n",
      " 0.7704918032786885\n",
      "f1_score beta\n",
      " 0.7885906040268457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1292,    7],\n",
       "       [  14,   47]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "ada_1_preds = ada_1_tune.predict(xtest)\n",
    "print('accuracy_score\\n',accuracy_score(ytest,ada_1_preds))\n",
    "print('precision_score\\n',precision_score(ytest,ada_1_preds))\n",
    "print('recall_score\\n',recall_score(ytest,ada_1_preds))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,ada_1_preds, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,ada_1_preds)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,ada_1_preds)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,ada_1_preds)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,ada_1_preds)\n",
    "confusion_matrix(ytest,ada_1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fantastic-franklin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START criterion=gini, n_estimators=3000...........................\n",
      "[CV 1/5; 1/1] END .........criterion=gini, n_estimators=3000; total time=  17.9s\n",
      "[CV 2/5; 1/1] START criterion=gini, n_estimators=3000...........................\n",
      "[CV 2/5; 1/1] END .........criterion=gini, n_estimators=3000; total time=  17.9s\n",
      "[CV 3/5; 1/1] START criterion=gini, n_estimators=3000...........................\n",
      "[CV 3/5; 1/1] END .........criterion=gini, n_estimators=3000; total time=  17.6s\n",
      "[CV 4/5; 1/1] START criterion=gini, n_estimators=3000...........................\n",
      "[CV 4/5; 1/1] END .........criterion=gini, n_estimators=3000; total time=  18.1s\n",
      "[CV 5/5; 1/1] START criterion=gini, n_estimators=3000...........................\n",
      "[CV 5/5; 1/1] END .........criterion=gini, n_estimators=3000; total time=  18.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "rfc_1 = RandomForestClassifier()\n",
    "rfc_1_params  = {\n",
    "    \"n_estimators\":[3000],\n",
    "    \"criterion\" : ['gini'],\n",
    "}\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "rfc_1_tune = GridSearchCV(estimator = rfc_1, param_grid = rfc_1_params, cv = 5, scoring=score_f1_beta, return_train_score = True, verbose = 10)\n",
    "rfc_1_tune.fit(xtrain, ytrain)\n",
    "rfc_1_tune.best_params_\n",
    "filename = 'RFC25.sav'\n",
    "pickle.dump(rfc_1_tune, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "czech-great",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      " 0.9772058823529411\n",
      "precision_score\n",
      " 1.0\n",
      "recall_score\n",
      " 0.4918032786885246\n",
      "f1_score beta\n",
      " 0.5474452554744526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1299,    0],\n",
       "       [  31,   30]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_1_preds = rfc_1_tune.predict(xtest)\n",
    "print('accuracy_score\\n',accuracy_score(ytest,rfc_1_preds))\n",
    "print('precision_score\\n',precision_score(ytest,rfc_1_preds))\n",
    "print('recall_score\\n',recall_score(ytest,rfc_1_preds))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,rfc_1_preds, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,rfc_1_preds)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,rfc_1_preds)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,rfc_1_preds)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,rfc_1_preds)\n",
    "confusion_matrix(ytest,rfc_1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tracked-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5; 1/1] START activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs\n",
      "[CV 1/5; 1/1] END activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs; total time=   1.7s\n",
      "[CV 2/5; 1/1] START activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs\n",
      "[CV 2/5; 1/1] END activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs; total time=   1.8s\n",
      "[CV 3/5; 1/1] START activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs\n",
      "[CV 3/5; 1/1] END activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs; total time=   1.8s\n",
      "[CV 4/5; 1/1] START activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs\n",
      "[CV 4/5; 1/1] END activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs; total time=   1.6s\n",
      "[CV 5/5; 1/1] START activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs\n",
      "[CV 5/5; 1/1] END activation=tanh, alpha=0.001, learning_rate=constant, solver=lbfgs; total time=   1.5s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "parameter_space = {\n",
    "    'activation': ['tanh'],\n",
    "    'solver': [ 'lbfgs'],\n",
    "    'alpha': [.001],\n",
    "    'learning_rate': ['constant'],\n",
    "}\n",
    "score_f1_beta = make_scorer(fbeta_score, beta=2)\n",
    "mlp_gs = MLPClassifier(max_iter=10000)\n",
    "clf = GridSearchCV(mlp_gs, parameter_space, cv=5, scoring=score_f1_beta, verbose=10)\n",
    "clf.fit(xtrain, ytrain)\n",
    "clf.best_params_\n",
    "import pickle\n",
    "filename = 'MLP25%.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "regulation-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      " 0.986764705882353\n",
      "precision_score\n",
      " 0.864406779661017\n",
      "recall_score\n",
      " 0.8360655737704918\n",
      "f1_score beta\n",
      " 0.8415841584158417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1291,    8],\n",
       "       [  10,   51]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_preds = clf.predict(xtest)\n",
    "print('accuracy_score\\n',accuracy_score(ytest,clf_preds))\n",
    "print('precision_score\\n',precision_score(ytest,clf_preds))\n",
    "print('recall_score\\n',recall_score(ytest,clf_preds))\n",
    "print('f1_score beta\\n',fbeta_score(ytest,clf_preds, beta=2.0))\n",
    "grid_lr_acc_acc_sc=accuracy_score(ytest,clf_preds)\n",
    "grid_lr_acc_pr_sc=precision_score(ytest,clf_preds)\n",
    "grid_lr_acc_rec_sc=recall_score(ytest,clf_preds)\n",
    "grid_lr_acc_f1_sc=f1_score(ytest,clf_preds)\n",
    "confusion_matrix(ytest,clf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "difficult-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC log:  0.9399285705271394\n",
      "AUC_ROC ada:  0.8825515213468116\n",
      "AUC_ROC svc:  0.9570918360908139\n",
      "AUC_ROC rfc:  0.7459016393442623\n",
      "AUC_ROC mlp:  0.9149534951223515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC_ROC log: \", roc_auc_score(ytest, lrgpytest_w))\n",
    "print(\"AUC_ROC ada: \", roc_auc_score(ytest, ada_1_preds))\n",
    "print(\"AUC_ROC svc: \", roc_auc_score(ytest, scv_1_preds1))\n",
    "print(\"AUC_ROC rfc: \", roc_auc_score(ytest, rfc_1_preds))\n",
    "print(\"AUC_ROC mlp: \", roc_auc_score(ytest,clf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-importance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
